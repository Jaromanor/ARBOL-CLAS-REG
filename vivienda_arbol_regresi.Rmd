---
title: "Regresi√≥n"
author: "JARO"
date: "2025-05-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. CONTEXTO

Se realizar√° un ejercicio de √°rbol de decisi√≥n tipo regresi√≥n, sin uso de mlr3.

La data es "Boston" del paquete MASS, la variable objetivo es "medv" que corresponde al valor medio de las viviendas en miles de d√≥lares y tiene 13 variables predictoras.

Se usar√° rpart para entrenar modelo y caret para validaci√≥n cruzada y tuning

```{r}
# Cargar librer√≠as
library(MASS)       # para la data Boston
library(rpart)      # para √°rbol de regresi√≥n
library(caret)      # para ML completo
library(rpart.plot) # para visualizar el √°rbol
```

```{r}
data("Boston")
str(Boston)
summary(Boston)
```

# 2. Partici√≥n data set

Por defecto, createDataPartition() devuelve una lista. Pero si pones:

list = FALSE

entonces te devuelve directamente un vector de √≠ndices (n√∫meros de fila), m√°s f√°cil de usar con subconjuntos de data.frame.

El muestreo es estratificado sobre la variable objetivo y con reposici√≥n FALSE

```{r}
set.seed(123)
train_index<-createDataPartition(Boston$medv,p=0.8,list = FALSE)
train_data<-Boston[train_index,]
test_data<-Boston[-train_index,]
```

# 3. Preprocesamiento (normalizaci√≥n, detecci√≥n de NA)

```{r}
# Revisar calidad de datos
library(dlookr)
diagnose(Boston)
```

```{r}
#Escalar

preproc<-preProcess(train_data,method = c("center","scale")) #con caret
train_scaled<-predict(preproc,train_data)
test_scaled<-predict(preproc,test_data)


#Si no queremos escalar la variable respuesta
#preproc <- preProcess(train_data[, -14], method = c("center", "scale"))  # sin medv
#train_scaled <- cbind(
#  predict(preproc, train_data[, -14]),
#  medv = train_data$medv
#)
#test_scaled <- cbind(
#  predict(preproc, test_data[, -14]),
#  medv = test_data$medv
#)



```


# 4. Entrenamiento con Validaci√≥n Cruzada

```{r}
# Control de validaci√≥n cruzada
ctrl<-trainControl(
  method = "cv",
  number = 10,
  verboseIter = TRUE
)

# Modelo inicial de √°rbol de regresi√≥n con tuning b√°sico
set.seed(123)
modelo_rpart<-train(
  medv~.,
  data=train_scaled,
  method="rpart",
  trControl =ctrl,
  tuneLength=10 # probar 10 valores de cp autom√°ticamente
)

# con expand.grid()
#grid <- expand.grid(cp = seq(0.001, 0.05, by = 0.005))

#modelo <- train(
#  medv ~ .,
#  data = train_scaled,
#  method = "rpart",
#  trControl = ctrl,
#  tuneGrid = grid,  # usamos tuneGrid en lugar de tuneLength
#  metric = "MAE"    #cambia optimizaci√≥n por MAE, por defecto es RMSE
#)
# Esto probar√° valores espec√≠ficos de cp: 0.001, 0.006, 0.011, ..., 0.046.

```

# 5. Resultados del tuning

```{r}
print(modelo_rpart)
plot(modelo_rpart)
modelo_rpart$finalModel$variable.importance
```
Muestra los valores probados de cp (complexity parameter).
Elige autom√°ticamente el mejor seg√∫n RMSE (Root Mean Squared Error) promedio de los folds.

Registr√≥ que **No pre-processing** El preprocesamiento no fue hecho desde caret, o no se registr√≥ porque fue aplicado antes manualmente (como hicimos con preProcess())

Prob√≥ diferentes valores del par√°metro cp (complexity parameter) y calcul√≥ el rendimiento promedio en validaci√≥n cruzada con 3 m√©tricas

De todos los modelos probados, el que tuvo el menor RMSE promedio en CV fue el elegido.

Ese modelo us√≥ cp = 0.0071, y fue entrenado completamente con esos hiperpar√°metros.


Respecto a la importancia de las variables:

- rm (n√∫mero de habitaciones) y lstat (porcentaje de poblaci√≥n de bajo nivel     socioecon√≥mico) son las m√°s influyentes.

- chas (cerca del r√≠o Charles) tiene muy poca importancia.





# 6. Visualizaci√≥n del √°rbol final

```{r}
rpart.plot(modelo_rpart$finalModel)
#Si escalaste medv tambi√©n	Las hojas muestran z-scores (desviaciones est√°ndar)
#Si no escalaste medv	Las hojas muestran valores promedio reales
```

# 6.1 Minireporte
Objetivo
Se construy√≥ un modelo predictivo basado en √°rboles de regresi√≥n (rpart) con el fin de estimar el valor medio de viviendas (medv) utilizando 13 caracter√≠sticas sociodemogr√°ficas y urbanas del dataset Boston.

Detalles del modelo:

- Modelo utilizado: √Årbol de regresi√≥n (rpart)
- Conjunto de datos: 407 observaciones de entrenamiento
- M√©todo de evaluaci√≥n: Validaci√≥n cruzada de 10 pliegues
- Preprocesamiento: Las variables predictoras fueron escaladas (media 0,         desviaci√≥n 1); la variable objetivo se mantuvo en su escala original (valor    en miles de d√≥lares).

Desempe√±o del modelo (validaci√≥n cruzada)

- Mejor par√°metro de complejidad (cp): 0.0071
- Error cuadr√°tico medio (RMSE): 0.50
‚Üí El modelo se equivoca, en promedio, en ¬±5,000 USD.
- Error absoluto medio (MAE): 0.35
‚Üí El error medio sin penalizaci√≥n por errores grandes es de ¬±3,500 USD.
- R¬≤ (coeficiente de determinaci√≥n): 0.74
‚Üí El modelo explica el 74% de la variabilidad en los precios de vivienda.

Estos resultados indican que el modelo tiene buena capacidad predictiva, especialmente considerando su simplicidad.

Principales variables utilizadas por el modelo

El √°rbol seleccion√≥ autom√°ticamente las variables m√°s relevantes para predecir el valor de las viviendas. A continuaci√≥n se listan las 5 m√°s importantes:

| Variable | Descripci√≥n                                  | Importancia relativa |
| -------- | -------------------------------------------- | -------------------- |
| `rm`     | N√∫mero medio de habitaciones por vivienda    | Alta                 |
| `lstat`  | % de poblaci√≥n de bajo nivel socioecon√≥mico  | Alta                 |
| `indus`  | % de √°rea destinada a industria no minorista | Moderada             |
| `dis`    | Distancia media a centros de empleo          | Moderada             |
| `tax`    | Tasa de impuestos a la propiedad             | Moderada             |



# 7. Evaluaci√≥n en conjunto de prueba


```{r}
# Predicci√≥n

pred<-predict(modelo_rpart,newdata = test_scaled)

# Evaluaci√≥n

postResample(pred, test_scaled$medv)


#Desescalar la variable respuesta
# medias y escalas originales de medv
#media_medv <- preproc$mean["medv"]
#sd_medv <- preproc$std["medv"]

# volver a la escala original
#pred_desescalado <- pred * sd_medv + media_medv


```

```{r}
library(ggplot2)
df_resultados <- data.frame(
  Real = test_scaled$medv,
  Predicho = pred
)

ggplot(df_resultados, aes(x = Real, y = Predicho)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = "Valores Reales vs Predichos",
    x = "Valor Real (medv)",
    y = "Valor Predicho"
  ) +
  theme_minimal()

```


# 8. Exportaci√≥n del modelo para producci√≥n

Si es necesario integrarlo en una aplicaci√≥n o sistema:
```{r}
saveRDS(modelo_rpart, "modelo_rpart_boston.rds")
saveRDS(preproc, "preproc_boston.rds")
```
**saveRDS(modelo, "modelo_rpart_boston.rds")**
- Guarda el modelo entrenado (modelo) en un archivo con formato .rds.
- El archivo se llama "modelo_rpart_boston.rds" y se guarda en tu carpeta de     trabajo actual.

**saveRDS(preproc, "preproc_boston.rds")**
- Guarda la "receta de preprocesamiento" (preproc) en otro archivo .rds.
- Esto es importante porque la misma transformaci√≥n aplicada al conjunto de      entrenamiento debe aplicarse a nuevos datos en producci√≥n.

üéØ As√≠ garantizas que nuevas observaciones sean escaladas o transformadas igual que el training.


Y para usarlo en producci√≥n:
```{r}
modelo <- readRDS("modelo_rpart_boston.rds")
preproc <- readRDS("preproc_boston.rds")
nueva_data <- predict(preproc, newdata = nueva_data)
predict(modelo, newdata = nueva_data)
```
**modelo <- readRDS("modelo_rpart_boston.rds")**
- Carga desde disco el modelo de √°rbol de regresi√≥n ya entrenado.
- El objeto modelo ya est√° listo para predecir.

**preproc <- readRDS("preproc_boston.rds")**
- Carga la receta de preprocesamiento usada en el entrenamiento.
- Esto es crucial para aplicar las mismas transformaciones (centrado, escalado,   etc.) a nuevos datos.

**nueva_data <- predict(preproc, newdata = nueva_data)**
- Aplica la misma transformaci√≥n que se aplic√≥ al entrenamiento (centrado y      escalado) a nuevos datos (nueva_data).
- nueva_data debe tener las mismas columnas predictoras que usaste               originalmente.

üéØ Esto asegura que el modelo no reciba datos "en otra escala" o mal preparados.

**predict(modelo, newdata = nueva_data)**
- Aplica el modelo ya entrenado a los nuevos datos (ya preprocesados) y          devuelve las predicciones.
- Es el paso final para usar el modelo en la pr√°ctica.







