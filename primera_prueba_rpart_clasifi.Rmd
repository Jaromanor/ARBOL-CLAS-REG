---
title: "CLASIFICACION"
author: "JARO"
date: "2025-05-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# CONTEXTO

Se desarrollará un ejercicio con un enfoque explicativo (análisis estadístico, interpretación estructural del modelo) utilizando rpart y posteriormente un enfoque predictivo utilizando mlr3.


El data set: kyphosis de rpart

- Datos de una cirugía de corrección de la columna vertebral (kyphosis = joroba     espinal). Aparición de joroba después de la operación.

- Variables predictoras: Edad, Número de vértebras involucradas, Posición inicial.

- Variable objetivo: Kyphosis (SÍ/NO)


```{r}
library(rpart)
data(kyphosis)
str(kyphosis)
```


## Enfoque Explicativo

Construir un árbol de decisión con rpart que:

- Prediga la presencia de kyphosis post cirugía (clasificación).

- Permita interpretar reglas de decisión.

- Aplique poda (pre- y post-), y ajuste del crecimiento.

- Analice los resultados desde una perspectiva explicativa, no meramente         predictiva.


### 1. Particionamos en Training y Test

La librería "rpart" no tiene una función para esta tarea, por eso utilizamos la función "createDataPartition" de la librería "CARET" ya que es más simple y hace el muestreo estratificado. Se puede con la función base "sample" pero es más complicado. Se puede con el ecosistema mlr3 pero se debe encapsular en un task.

```{r}
library(caret)
set.seed(123)
indices<-createDataPartition(kyphosis$Kyphosis,p=0.7,list = FALSE)
train<-kyphosis[indices,]
test<-kyphosis[-indices,]
```

### 2. Entrenamiento del modelo

```{r}
arbol_ini<-rpart(Kyphosis~.,data = kyphosis,method = "class")
```

Internamente, rpart:

- Divide los datos según la variable que más reduce el índice de Gini
- Crea nodos hasta que se cumple un criterio de parada
- Almacena un árbol completo sin podar inicialmente

### 3. Visualizar Árbol

```{r}
library(rpart.plot)
rpart.plot(arbol_ini, type = 3, extra = 1)
```

### 4. Evaluar complejidad del árbol


```{r}
printcp(arbol_ini)
```

printcp(): Muestra la tabla de complejidad del árbol (cp = complexity parameter) y Evalúa cómo cambia el error de validación cruzada al eliminar nodos.

El entrenamiento solo usó dos variables: "Age" y "Start"

Root node error: 17/81 = 0.20988: La clase mayoritaria es que NO tiene problemas en la columna o "absent" pero que de 81 observaciones 17 SÍ presentan problemas en la columna "present". También se puede interpretar como Error de clasificación inicial (sin splits). Esto es el error relativo base para comparar con los siguientes splits. Desde luego tomando como base NO.



- nsplit: cantidad de divisiones.

- rel error: error relativo del árbol entrenado, comparado con el error del      nodo raíz.

- xerror: error de validación cruzada. Por defecto 10 folds.

xerror = (error de clasificación promedio en los folds) ÷ (error del nodo raíz)
Cuanto más bajo mejor generaliza

xerror= (numero de predicciones incorrectas en los folds)/(total de observaciones en los folds)

- xstd: desviación estándar de xerror

- Objetivo: encontrar el valor óptimo de cp que minimiza el xerror.


Se escoge el menor xerror o el xerror menor a 1-SE=xerror(mínimo)+xstd

La fila 3 corresponde a todo el árbol sin poda








### 5. Poda del Árbol

```{r}
arbol_podado <- prune(arbol_ini,
                      cp = arbol_ini$cptable[which.min(arbol_ini$cptable[, "xerror"]), "CP"])
```

Elige el árbol más pequeño con el menor error cruzado.

prune() poda ramas que no mejoran el rendimiento general.

El árbol resultante es más interpretable y evita sobreajuste.


### 6. Visualizar Árbol Podado

```{r}
rpart.plot(arbol_podado, type = 3, extra = 104)
```

### 7. Predicción con Poda

```{r}
pred_test_1 <- predict(arbol_podado, newdata = test, type = "class")
```


### 8. Evaluación del desempeño con Poda

```{r}
table(Predicted = pred_test_1, Actual = test$Kyphosis)
```
Métricas con Poda

VN: 19
FN:  5
VP:  0
FP:  0

Ahora miremos sin Poda

### 9. Predicción sin Poda

```{r}
pred_test_2 <- predict(arbol_ini, newdata = test, type = "class")
```


### 10. Evaluación del desempeño sin Poda

```{r}
table(Predicted = pred_test_2, Actual = test$Kyphosis)
```
Métricas sin Poda

VN: 14
FN:  1
VP:  5
FP:  4

La idea es explicarle a las personas la posibilidad de tener joroba después de la operación basado en la edad y la parte de la columna o vertebra intervenida.

1. Quiero hacer un modelo estricto que no deje pasar ninguna persona con posbilidad de tener joroba después de la operación para que una vez intervenido entonces empiece a tomar medidas.

Entonces se aumenta la sensibilidad debo escoger el modelo sin poda

2. Quiero hacer un modelo más laxo que deje pasar personas con probabilidades de tener joroba, esto porque si se diagnostica mal FP las medidas para evitar la joroba pueden poner en peligro la movilidad del paciente

Entonces debo tomar el modelo con poda.







