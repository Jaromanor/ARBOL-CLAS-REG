---
title: "Aceptación_Carros"
author: "JARO"
date: "2025-05-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. CONTEXTO

Se desarrollará un ejercicio con un enfoque explicativo (análisis estadístico, interpretación estructural del modelo) utilizando rpart y posteriormente un enfoque predictivo utilizando mlr3.

## 1.1 El data set: car

Este data set muestra la preferencia de los carros basado en algunas características. La variable aceptabilidad (targed) presenta 4 valoraciones.

## 1.2 Carga Data Set y adecuaciones.


```{r}
#Las observaciones
download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data", "car.data")
```

```{r}
#Los nombres de las variables
download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.names", "car.names")
```
Como habrás notado, nuestros datos tienen una extensión de archivo no convencional: .data. En R no existe una función específica para leer archivos con esta extensión, similar a red.csv() o read.dat(), las cuales nos facilitan tarea de importar archivos de formatos específicos. Lo mismmo pasa con el archivo con su descripción, que tiene la extensión .name.

Necesitamos explorar estos archivos para saber cómo podemos leerlos. Para estos casos, usamos la función readLines(), que lee archivos, línea por línea, independientemente de su extensión o formato. con el argumento n = 10 indicamos que sólo deseamos leer las primeras diez líneas de cada archivo.

Empezamos con los datos.

```{r}
readLines("car.data",n=10)
```
El archivo de datos parece ser una tabla de datos rectangular, con columnas separadas por comas. Entonces leer este archivo es fácil. El único inconveniente que tenemos es que nos faltan los nombres de cada columna.

Podemos usar read_table() para leer este archivo. Esta función está diseñada para leer tablas de datos, es decir, con estructura rectangular (renglones y columnas).

Para asegurarnos que los datos serán leídos de manera correcta, especificamos que el separador de las columnas es una coma (sep = ",") y que no tenemos nombres de columna en nuestro archivo (header = FALSE). Asignamos el resultado al objeto carros.

```{r}
carros<-read.table("car.data",sep = ",")
```

```{r}
names<-c("preciocompra","preciomantenimiento","#puertas",
         "#personas","tamañomaletero","seguridad","aceptabilidad")
```

```{r}
names(carros)<-names
```


```{r}
str(carros)
```
Establecemos como factores. Pero hacerlo automatizado para poder reutilizar el script

```{r}
library(dplyr)
carros<-carros%>%
  mutate(across(where(is.character),as.factor))
```


# 2. Enfoque Explicativo

Inicialmente revisamos el balanceo:

```{r}
prop.table(table(carros$aceptabilidad))
```

Las opiniones mejor valoradas están desbalanceadas, sin embargo, continuamos el ejercicio.

## 2.1 Set: Entrenamiento y Prueba

```{r}
library(caret)
indices<-createDataPartition(carros$aceptabilidad,p=0.7,list = FALSE)
train<-carros[indices,]
test<-carros[-indices,]
```

Verificamos que todas las categorías de nuestra variable target en el set de entrenamiento estén presentes:

```{r}
prop.table(table(train$aceptabilidad))
```

## 2.2 Entrenamiento del modelo

```{r}
library(rpart)
car_ini<-rpart(aceptabilidad~.,data=train,method = "class")
```

## 2.3 Visualizar Árbol

```{r}
library(rpart.plot)
rpart.plot(car_ini, type = 3, extra = 104)
```

## 2.4 Evaluar complejidad del árbol


```{r}
printcp(car_ini)
```

El algoritmo eliminó la variable: # Puertas

Root node error: 364/1211 toma unacc como clase mayoritaria

Prácticamente me indica que no haga poda ya que el xerror de validación cruzada menor está en el cp inferior o lo que es lo mismo en el último nivel del árbol estimado.

## 2.5 Predicción

```{r}
pred_test <- predict(car_ini, newdata = test, type = "class")
```

## 2.6 Evaluación

```{r}
table(Predicted = pred_test, Actual = test$aceptabilidad)
```

# 3. Enfoque predicitivo: MLR3

```{r}
library(mlr3)
library(mlr3learners)       # para incluir learners como rpart
library(mlr3verse)          # entorno completo de mlr3
library(mlr3viz)            # visualización opcional
library(mlr3measures)       # métricas extra
library(rpart.plot)         # para visualizar el árbol
library(rpart)
library(mlr3fselect)
```

## 3.1 Creación de Tarea

Creamos la tarea de clasificación o el task

```{r}
task_ini<-TaskClassif$new(
  id="car",
  backend=carros,
  target="aceptabilidad"
)
task_ini
```

## 3.2 Partición set de datos: Train - Test

Particionamos el data SET: 80% entrenamiento y 20% prueba. Cada set tendrá su propio Task para evitar intervenir el original.

```{r}
set.seed(1234)
rsmp_car<-rsmp("holdout",ratio=0.8)
```

Para que el reparto sea estratificado, es necesario indicar en el task qué columna o columnas se emplea como stratum. Solo para variables cualitativas.

```{r}
task_ini$col_roles$stratum<-"aceptabilidad"
```

Tomo el objeto “task_datos” (mi tarea de machine learning que contiene mi data original). Entonces $instantiate toma ese objeto y le aplica el método rsmp_holdout. Esto genera los índices de data train y test.

```{r}
rsmp_car$instantiate(task = task_ini)
```

Obtengo los índices

```{r}
id_train<-rsmp_car$train_set(i=1)
id_test<-rsmp_car$test_set(i=1)
```

Crea una copia del objeto task_datos y sobre esa copia, filtra para quedarte solo con las observaciones de entrenamiento, usando los índices id_train. Guarda el resultado en task_train.

```{r}
task_train<-task_ini$clone()$filter(id_train)
task_test<-task_ini$clone()$filter(id_test)
```


## 3.3 Preprocesamiento
El preprocesado engloba todas aquellas transformaciones realizadas sobre los datos con el objetivo que puedan ser interpretados por el algoritmo de machine learning lo más eficientemente posible.

Aca se van a escalar y recodificar las variables cualitativas a dummis. Además para no alterar los task originales se crearan task de preprocesamiento.

Creamos la tarea de preprocesamiento o nuestro pipeline:

```{r}
preproces_pipeline<-po("scale",param_vals=list(center=TRUE,scale=TRUE))%>>%
  po("encode",param_vals=list(method="one-hot"))
```

```{r}
preproces_pipeline$train(task_train)
```

Ejecutamos el pipeline sobre las tareas de entrenamiento y prueba, pero creando nuevos objetos:

```{r}
task_train_pre<-preproces_pipeline$predict(task_train)[[1]]$clone()
task_test_pre<-preproces_pipeline$predict(task_train)[[1]]$clone()
```
¿Por qué [[1]]?
El pipeline devuelve una lista de resultados (list(task_procesado)) porque los PipeOp pueden tener múltiples salidas (e.g., bifurcaciones).







