knitr::opts_chunk$set(echo = TRUE)
library(rpart)
data(kyphosis)
library(rpart)
data(kyphosis)
str(kyphosis)
library(mlr3verse)
library(caret)
library(caret)
set.seed(123)
indices<-createDataPartition(kyphosis$Kyphosis,p=0.7,list = FALSE)
train<-kyphosis[indices,]
test<-kyphosis[-indices,]
View(train)
?rpart
arbol_ini<-rpart(kyphosis~.,data = kyphosis,method = "class")
View(kyphosis)
arbol_ini<-rpart(Kyphosis~.,data = kyphosis,method = "class")
library(rpart.plot)
install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(arbol_ini, type = 3, extra = 104)
?rpart.plot
library(rpart.plot)
rpart.plot(arbol_ini, type = 3, extra = 106)
library(rpart.plot)
rpart.plot(arbol_ini, type = 3, extra = 106)
View(kyphosis)
library(rpart.plot)
rpart.plot(arbol_ini, type = 3, extra = 108)
library(rpart.plot)
rpart.plot(arbol_ini, type = 3, extra = 0)
library(rpart.plot)
rpart.plot(arbol_ini, type = 3, extra = 1)
library(rpart.plot)
rpart.plot(arbol_ini, type = 3, extra = 10)
library(rpart.plot)
rpart.plot(arbol_ini, type = 3, extra = 1)
library(rpart.plot)
rpart.plot(arbol_ini, type = 3, extra = 8)
library(rpart.plot)
rpart.plot(arbol_ini, type = 3, extra = 104)
library(rpart.plot)
rpart.plot(arbol_ini, type = 3, extra = 108)
library(rpart.plot)
rpart.plot(arbol_ini, type = 3, extra = 2)
library(rpart.plot)
rpart.plot(arbol_ini, type = 3, extra = 104)
printcp(arbol_ini)
arbol_podado <- prune(arbol_ini,
cp = arbol_ini$cptable[which.min(arbol_ini$cptable[, "xerror"]), "CP"])
rpart.plot(arbol_podado, type = 3, extra = 104)
arbol_ini
printcp(arbol_ini)
pred_test <- predict(arbol_podado, newdata = test, type = "class")
pred_test
table(Predicted = pred_test, Actual = test$Kyphosis)
View(kyphosis)
table(kyphosis$Kyphosis)
library(rpart.plot)
rpart.plot(arbol_ini, type = 3, extra = 1)
library(CDR)
# Paso 1: cargar librerías
library(rpart)
library(rpart.plot)
# Paso 2: crear el dataframe
datos <- data.frame(
Día = 1:15,
Tipo_de_día = c("Soleado", "Soleado", "Lluvia", "Nublado", "Lluvia",
"Lluvia", "Soleado", "Nublado", "Soleado", "Lluvia",
"Soleado", "Nublado", "Nublado", "Lluvia", "Soleado"),
Humedad = c("Fuerte", "Fuerte", "Fuerte", "Fuerte", "Débil",
"Débil", "Fuerte", "Débil", "Débil", "Débil",
"Débil", "Fuerte", "Débil", "Fuerte", "Fuerte"),
Viento = c("Débil", "Fuerte", "Débil", "Débil", "Débil",
"Fuerte", "Débil", "Fuerte", "Débil", "Débil",
"Fuerte", "Fuerte", "Débil", "Fuerte", "Fuerte"),
Decisión = c("NO", "NO", "SÍ", "SÍ", "SÍ",
"NO", "NO", "SÍ", "SÍ", "SÍ",
"SÍ", "SÍ", "SÍ", "SÍ", "NO")
)
# Convertir variables categóricas
datos$Tipo_de_día <- as.factor(datos$Tipo_de_día)
datos$Humedad <- as.factor(datos$Humedad)
datos$Viento <- as.factor(datos$Viento)
datos$Decisión <- as.factor(datos$Decisión)
set.seed(123)
idx <- sample(1:15, size = 10)
train <- datos[idx, ]
test <- datos[-idx, ]
arbol <- rpart(Decisión ~ Tipo_de_día + Humedad + Viento,
data = train,
method = "class",
control = rpart.control(cp = 0))
printcp(arbol)
arbol_podado <- prune(arbol, cp = cp_min)
cp_min <- arbol$cptable[which.min(arbol$cptable[, "xerror"]), "CP"]
arbol_podado <- prune(arbol, cp = cp_min)
arbol_podado
rpart.plot(arbol_podado, type = 3, extra = 104)
library(rpart)
library(caret)
library(rpart.plot)
printcp(arbol_ini)
arbol_ini$cptable
arbol_ini$cptable[, "xerror"]
arbol_ini$cptable[, "xerror", "CP"]
arbol_ini$cptable[,c("xerror", "CP")]
knitr::opts_chunk$set(echo = TRUE)
arbol_podado <- prune(arbol_ini,
cp = arbol_ini$cptable[which.min(arbol_ini$cptable[, "xerror"]), "CP"])
rpart.plot(arbol_podado, type = 3, extra = 104)
pred_test <- predict(arbol_podado, newdata = test, type = "class")
View(test)
library(rpart)
data(kyphosis)
str(kyphosis)
library(caret)
set.seed(123)
indices<-createDataPartition(kyphosis$Kyphosis,p=0.7,list = FALSE)
train<-kyphosis[indices,]
test<-kyphosis[-indices,]
arbol_ini<-rpart(Kyphosis~.,data = kyphosis,method = "class")
library(rpart.plot)
rpart.plot(arbol_ini, type = 3, extra = 1)
printcp(arbol_ini)
arbol_podado <- prune(arbol_ini,
cp = arbol_ini$cptable[which.min(arbol_ini$cptable[, "xerror"]), "CP"])
rpart.plot(arbol_podado, type = 3, extra = 104)
pred_test <- predict(arbol_podado, newdata = test, type = "class")
table(Predicted = pred_test, Actual = test$Kyphosis)
pred_test <- predict(arbol_ini, newdata = test, type = "class")
pred_test_1 <- predict(arbol_podado, newdata = test, type = "class")
table(Predicted = pred_test_1, Actual = test$Kyphosis)
pred_test_2 <- predict(arbol_ini, newdata = test, type = "class")
table(Predicted = pred_test_2, Actual = test$Kyphosis)
table(Predicted = pred_test_2, Actual = test$Kyphosis)
table(Predicted = pred_test_1, Actual = test$Kyphosis)
arbol_ini$cptable[which.min(arbol_ini$cptable[, "xerror"]), "CP"])
arbol_ini$cptable[which.min(arbol_ini$cptable[, "xerror"]), "CP"]
View(kyphosis)
knitr::opts_chunk$set(echo = TRUE)
download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data", "car.data")
#Los nombres de las variables
download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.names", "car.names")
readLines("car.data",n=10)
carros<-read.table("car.data",sep = ",")
View(carros)
names<-c("preciocompra","preciomantenimiento","#puertas",
"#personas","tamañomaletero","seguridad","aceptabilidad")
names(carros)<-names
View(carros)
str(carros)
View(carros)
library(dplyr)
carros<-carros%>%
mutate(across(case_when(is.character),as.factor))
library(dplyr)
carros<-carros%>%
mutate(across(case_when(is.character),~as.factor))
library(dplyr)
carros<-carros%>%
mutate(across(where(is.character),as.factor))
str(carros)
summary(carros)
prop.table(table(carros$aceptabilidad))
library(caret)
indices<-createDataPartition(carros$aceptabilidad,p=0.7,list = FALSE)
train<-carros[indices,]
test<-carros[-indices,]
prop.table(table(train$aceptabilidad))
library(rpart)
library(rpart)
car_ini<-rpart(aceptabilidad~.,data=train,method = "class")
car_ini
library(rpart.plot)
rpart.plot(car_ini, type = 3, extra = 104)
printcp(car_ini)
View(train)
table(train$aceptabilidad)
pred_test <- predict(car_ini, newdata = test, type = "class")
table(Predicted = pred_test, Actual = test$aceptabilidad)
library(mlr3verse)
library(mlr3)
library(mlr3learners)       # para incluir learners como rpart
library(mlr3verse)          # entorno completo de mlr3
library(mlr3viz)            # visualización opcional
library(mlr3measures)       # métricas extra
library(rpart.plot)         # para visualizar el árbol
library(rpart)
set.seed(123)
split<-partition(task,ratio = 0.7)
task<-TaskClassif$new(
id="carros",
backend = "carros",
target = "aceptabilidad"
)
#Las observaciones
download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data", "car.data")
#Los nombres de las variables
download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.names", "car.names")
carros<-read.table("car.data",sep = ",")
names<-c("preciocompra","preciomantenimiento","#puertas",
"#personas","tamañomaletero","seguridad","aceptabilidad")
names(carros)<-names
str(carros)
task<-TaskClassif$new(
id="carros",
backend = "carros",
target = "aceptabilidad"
)
library(dplyr)
carros<-carros%>%
mutate(across(where(is.character),as.factor))
task<-TaskClassif$new(
id="carros",
backend = "carros",
target = "aceptabilidad"
)
task<-TaskClassif$new(
id="carros",
backend = carros,
target = "aceptabilidad"
)
set.seed(123)
split<-partition(task,ratio = 0.7)
#Definimos el learner
learner<-lrn("classif.rpart",predict_type="response")
?msr
# Diseño de evaluación para cada subconjunto de variables
resampling<-rsmp("cv",folds=5)
# Métrica a optimizar (puedes cambiar por sensitivity si tu prioridad es captar "yes")
measure <- msr("sensitivity")
# Diseño de evaluación para cada subconjunto de variables
resampling<-rsmp("cv",folds=5)
# Métrica a optimizar (puedes cambiar por sensitivity si tu prioridad es captar "yes")
measure <- msr("classif.sensitivity")
# Selector: búsqueda secuencial hacia adelante o aleatoria random_search
fselector <- fs("sequential")
# Criterio de parada: 20 combinaciones
terminator <- trm("evals", n_evals = 20)
# Términos de la selección de variables
instance <- FSelectInstanceSingleCrit$new(
task = task,
learner = learner,
resampling = resampling,
measure = measure,
terminator = terminator
fselector = fselector
# Diseño de evaluación para cada subconjunto de variables
resampling<-rsmp("cv",folds=5)
# Métrica a optimizar (puedes cambiar por sensitivity si tu prioridad es captar "yes")
measure <- msr("classif.sensitivity")
# Selector: búsqueda secuencial hacia adelante o aleatoria random_search
fselector <- fs("sequential")
# Criterio de parada: 20 combinaciones
terminator <- trm("evals", n_evals = 20)
# Términos de la selección de variables
instance <- FSelectInstanceSingleCrit$new(
task = task,
learner = learner,
resampling = resampling,
measure = measure,
terminator = terminator,
fselector = fselector
)
library(mlr3fselect)
# Diseño de evaluación para cada subconjunto de variables
resampling<-rsmp("cv",folds=5)
# Métrica a optimizar (puedes cambiar por sensitivity si tu prioridad es captar "yes")
measure <- msr("classif.sensitivity")
# Selector: búsqueda secuencial hacia adelante o aleatoria random_search
fselector <- fs("sequential")
# Criterio de parada: 20 combinaciones
terminator <- trm("evals", n_evals = 20)
# Términos de la selección de variables
instance <- FSelectInstanceSingleCrit$new(
task = task,
learner = learner,
resampling = resampling,
measure = measure,
terminator = terminator,
fselector = fselector
)
library(mlr3fselect)
# Diseño de evaluación para cada subconjunto de variables
resampling<-rsmp("cv",folds=5)
# Métrica a optimizar (puedes cambiar por sensitivity si tu prioridad es captar "yes")
measure <- msr("classif.sensitivity")
# Selector: búsqueda secuencial hacia adelante o aleatoria random_search
fselector <- fs("sequential")
# Criterio de parada: 20 combinaciones
terminator <- trm("evals", n_evals = 20)
# Términos de la selección de variables
instance <- FSelectInstanceSingleCrit$new(
task = task,
learner = learner,
resampling = resampling,
measure = measure,
terminator = terminator,
fselector = fselector
)
# Diseño de evaluación para cada subconjunto de variables
resampling<-rsmp("cv",folds=5)
# Métrica a optimizar (puedes cambiar por sensitivity si tu prioridad es captar "yes")
measure <- msr("classif.sensitivity")
# Selector: búsqueda secuencial hacia adelante o aleatoria random_search
fselector <- fs("sequential")
# Criterio de parada: 20 combinaciones
terminator <- trm("evals", n_evals = 20)
# Términos de la selección de variables
library(mlr3fselect)
instance <- FSelectInstanceSingleCrit$new(
task = task,
learner = learner,
resampling = resampling,
measure = measure,
terminator = terminator,
fselector = fselector
)
# Diseño de evaluación para cada subconjunto de variables
resampling<-rsmp("cv",folds=5)
# Métrica a optimizar (puedes cambiar por sensitivity si tu prioridad es captar "yes")
measure <- msr("classif.sensitivity")
# Selector: búsqueda secuencial hacia adelante o aleatoria random_search
fselector <- fs("sequential")
# Criterio de parada: 20 combinaciones
terminator <- trm("evals", n_evals = 20)
# Términos de la selección de variables
library(mlr3fselect)
instance <- mlr3fselect::FSelectInstanceSingleCrit$new(
task = task,
learner = learner,
resampling = resampling,
measure = measure,
terminator = terminator,
fselector = fselector
)
# Diseño de evaluación para cada subconjunto de variables
resampling<-rsmp("cv",folds=5)
# Métrica a optimizar (puedes cambiar por sensitivity si tu prioridad es captar "yes")
measure <- msr("classif.sensitivity")
# Selector: búsqueda secuencial hacia adelante o aleatoria random_search
fselector <- fs("sequential")
# Criterio de parada: 20 combinaciones
terminator <- trm("evals", n_evals = 20)
# Términos de la selección de variables
library(mlr3fselect)
instance <- mlr3fselect::FSelectInstance$new(
task = task,
learner = learner,
resampling = resampling,
measure = measure,
terminator = terminator,
fselector = fselector
)
# Diseño de evaluación para cada subconjunto de variables
resampling<-rsmp("cv",folds=5)
# Métrica a optimizar (puedes cambiar por sensitivity si tu prioridad es captar "yes")
measure <- msr("classif.sensitivity")
# Selector: búsqueda secuencial hacia adelante o aleatoria random_search
fselector <- fs("sequential")
# Criterio de parada: 20 combinaciones
terminator <- trm("evals", n_evals = 20)
# Términos de la selección de variables
library(mlr3fselect)
instance <- mlr3fselect::FSelectInstance$new(
task = task,
learner = learner,
resampling = resampling,
measure = measure,
terminator = terminator,
fselector = fselector
)
# Diseño de evaluación para cada subconjunto de variables
resampling<-rsmp("cv",folds=5)
# Métrica a optimizar (puedes cambiar por sensitivity si tu prioridad es captar "yes")
measure <- msr("classif.sensitivity")
# Selector: búsqueda secuencial hacia adelante o aleatoria random_search
fselector <- fs("sequential")
# Criterio de parada: 20 combinaciones
terminator <- trm("evals", n_evals = 20)
# Términos de la selección de variables
library(mlr3fselect)
instance <- FSelectInstance$new(
task = task,
learner = learner,
resampling = resampling,
measure = measure,
terminator = terminator,
fselector = fselector
)
packageVersion("mlr3fselect")
# Diseño de evaluación para cada subconjunto de variables
resampling<-rsmp("cv",folds=5)
# Métrica a optimizar (puedes cambiar por sensitivity si tu prioridad es captar "yes")
measure <- msr("classif.sensitivity")
# Selector: búsqueda secuencial hacia adelante o aleatoria random_search
fselector <- fs("sequential")
# Criterio de parada: 20 combinaciones
terminator <- trm("evals", n_evals = 20)
# Términos de la selección de variables
library(mlr3fselect)
instance <- fselect(
task = task,
learner = learner,
resampling = resampling,
measure = measure,
terminator = terminator,
fselector = fselector
)
